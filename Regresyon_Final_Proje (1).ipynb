{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65caa219-42b2-4da2-b64c-29d07a2b2554",
   "metadata": {},
   "source": [
    "# FİNAL PROJE                                                                         ##### Şevval Şereflican"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534ffb6d-4517-4a1e-984a-f286b0eec84c",
   "metadata": {},
   "source": [
    "### 1.A.REGRESYON PROBLEMİ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce603661-0cf1-4e41-9027-210a00abc750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69412485-eb26-4cc2-9aeb-bea57ce2fbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veriyi yükleyelim\n",
    "df = pd.read_csv('train.csv')  \n",
    "\n",
    "# İlk 5 satıra bakalım\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c36df72-bba8-470e-9a6e-f11ea5a19a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     588 non-null    object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Veri seti hakkında genel bilgi\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10f18d88-3139-4503-98fe-933c33307e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolQC          1453\n",
       "MiscFeature     1406\n",
       "Alley           1369\n",
       "Fence           1179\n",
       "MasVnrType       872\n",
       "FireplaceQu      690\n",
       "LotFrontage      259\n",
       "GarageYrBlt       81\n",
       "GarageCond        81\n",
       "GarageType        81\n",
       "GarageFinish      81\n",
       "GarageQual        81\n",
       "BsmtFinType2      38\n",
       "BsmtExposure      38\n",
       "BsmtQual          37\n",
       "BsmtCond          37\n",
       "BsmtFinType1      37\n",
       "MasVnrArea         8\n",
       "Electrical         1\n",
       "Id                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eksik veri kontrolü\n",
    "df.isnull().sum().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f8f4f01-c99d-4b21-b87d-3451e9053879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam eksik veri sayısı: 0\n"
     ]
    }
   ],
   "source": [
    "# Çok fazla eksik olan sütunları çıkaralım\n",
    "df = df.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence'], axis=1)\n",
    "\n",
    "# 'Id' sütununu çıkaralım\n",
    "df = df.drop('Id', axis=1)\n",
    "\n",
    "# Kategorik değişkenlerde eksikleri 'None' ile doldur\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].fillna('None')\n",
    "\n",
    "# Sayısal değişkenlerde eksikleri medyan ile doldur\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in num_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Eksik verilerin tekrar kontrolü\n",
    "print(f\"Toplam eksik veri sayısı: {df.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7d5ac07-87ca-462f-bc75-afb5f15ea513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orijinal veri seti sütun sayısı: 76\n",
      "One-hot encoding sonrası sütun sayısı: 248\n"
     ]
    }
   ],
   "source": [
    "# Kategorik değişkenleri one-hot encoding ile sayısala çevirelim\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "print(f\"Orijinal veri seti sütun sayısı: {df.shape[1]}\")\n",
    "print(f\"One-hot encoding sonrası sütun sayısı: {df_encoded.shape[1]}\")\n",
    "\n",
    "# Satış fiyatı hedef değişkeni olarak ayıralım\n",
    "X = df_encoded.drop('SalePrice', axis=1)\n",
    "y = df_encoded['SalePrice']\n",
    "\n",
    "# Veri setini eğitim ve test olarak ayıralım\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbcc3423-1291-4315-887c-a2bb96173ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lineer Regresyon Performansı:\n",
      "MSE: 2757705912.80\n",
      "MAE: 20656.42\n",
      "R2: 0.6405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Model tanımlama\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Modeli eğitme\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Test setinde tahmin\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Performans ölçümleri\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Lineer Regresyon Performansı:\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"R2: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7507dfd3-06af-4799-b1c5-613880e9a024",
   "metadata": {},
   "source": [
    "### R² değeri yaklaşık %64, bu da modelin satış fiyatındaki değişimin %64’ünü açıklayabildiği anlamına gelir. MSE ve MAE ise fiyatların birimlerine göre yüksek görünüyor, ama bu normal çünkü konut fiyatları genelde büyük değerlerdir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96087be8-139b-475d-9bf9-06d2615985e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regressor Performansı:\n",
      "MSE: 2273211595.89\n",
      "MAE: 28141.80\n",
      "R2: 0.7036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Model tanımlama (k=5 varsayılan)\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "# Modeli eğitme\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Tahmin\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Performans ölçümü\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "mae_knn = mean_absolute_error(y_test, y_pred_knn)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "\n",
    "print(\"KNN Regressor Performansı:\")\n",
    "print(f\"MSE: {mse_knn:.2f}\")\n",
    "print(f\"MAE: {mae_knn:.2f}\")\n",
    "print(f\"R2: {r2_knn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef57b8c6-a7ef-4da3-9a31-2fa2af0081d3",
   "metadata": {},
   "source": [
    "### KNN R² performansı Lineer Regresyon’dan daha iyi (%70 civarı), ama MAE biraz daha yüksek olmuş."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2250663-c7f2-4bef-b74c-a6c4f896ca51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Performansı:\n",
      "MSE: 1841929467.72, MAE: 27535.11, R2: 0.7599\n",
      "\n",
      "Random Forest Performansı:\n",
      "MSE: 847842377.62, MAE: 17758.45, R2: 0.8895\n",
      "\n",
      "SVR Performansı:\n",
      "MSE: 7859359444.93, MAE: 59556.73, R2: -0.0246\n",
      "\n",
      "Voting Regressor Performansı:\n",
      "MSE: 2031654028.06, MAE: 25835.63, R2: 0.7351\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# 1) Decision Tree\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "mae_dt = mean_absolute_error(y_test, y_pred_dt)\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "\n",
    "# 2) Random Forest\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# 3) SVR (varsayılan parametrelerle, biraz yavaş olabilir)\n",
    "svr_model = SVR()\n",
    "svr_model.fit(X_train, y_train)\n",
    "y_pred_svr = svr_model.predict(X_test)\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "\n",
    "# 4) Voting Regressor (LR, RF ve SVR modellerinin birleşimi)\n",
    "voting_model = VotingRegressor(\n",
    "    estimators=[('lr', lr_model), ('rf', rf_model), ('svr', svr_model)]\n",
    ")\n",
    "voting_model.fit(X_train, y_train)\n",
    "y_pred_voting = voting_model.predict(X_test)\n",
    "mse_voting = mean_squared_error(y_test, y_pred_voting)\n",
    "mae_voting = mean_absolute_error(y_test, y_pred_voting)\n",
    "r2_voting = r2_score(y_test, y_pred_voting)\n",
    "\n",
    "# Sonuçları yazdır\n",
    "print(\"Decision Tree Performansı:\")\n",
    "print(f\"MSE: {mse_dt:.2f}, MAE: {mae_dt:.2f}, R2: {r2_dt:.4f}\\n\")\n",
    "\n",
    "print(\"Random Forest Performansı:\")\n",
    "print(f\"MSE: {mse_rf:.2f}, MAE: {mae_rf:.2f}, R2: {r2_rf:.4f}\\n\")\n",
    "\n",
    "print(\"SVR Performansı:\")\n",
    "print(f\"MSE: {mse_svr:.2f}, MAE: {mae_svr:.2f}, R2: {r2_svr:.4f}\\n\")\n",
    "\n",
    "print(\"Voting Regressor Performansı:\")\n",
    "print(f\"MSE: {mse_voting:.2f}, MAE: {mae_voting:.2f}, R2: {r2_voting:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a24e1ae-e534-4ec7-9f34-331fdc63a15e",
   "metadata": {},
   "source": [
    "##### Decision Tree: R² : %76, fena değil.\n",
    "\n",
    "##### Random Forest: R² : %89, şu an en iyi model bu görünüyor, hem MSE hem MAE düşük.\n",
    "\n",
    "##### SVR: Çok kötü performans (-0.02 R²) , parametre ayarı kesinlikle gerekli.(En basit düzeyde de parametre kullansamda kod çok yavaş olduğundan\n",
    "##### hep çalışmakta kaldı dolayısıyla gereksede parametre uygulamadım bu nedenle de  Svr büyük veri setlerinde çok verimli bir model değildir.)\n",
    "\n",
    "##### Voting Regressor (LR + RF + SVR): R² :%73, SVR’nin kötü etkisi olabilir, optimize etmek gerek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2bfcdfb-142d-4b15-93c4-ec59c0e61371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler (Random Forest): {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Optimize edilmiş Random Forest Performansı:\n",
      "MSE: 845773334.85\n",
      "MAE: 17739.75\n",
      "R2: 0.8897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"En iyi parametreler (Random Forest):\", grid_search_rf.best_params_)\n",
    "\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# Test performansı\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "print(\"Optimize edilmiş Random Forest Performansı:\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_best_rf):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_best_rf):.2f}\")\n",
    "print(f\"R2: {r2_score(y_test, y_pred_best_rf):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c268c1-1c44-446c-9e0e-ed69acc21703",
   "metadata": {},
   "source": [
    "##### Parametre optimizasyonu sonrası MSE ve MAE biraz düştü, bu da tahminlerin gerçek değerlere biraz daha yakınlaştığını gösterir.\n",
    "\n",
    "##### R² skoru da hafifçe yükseldi, yani model verinin varyansını biraz daha iyi açıklıyor.\n",
    "\n",
    "##### Ancak, performans iyileşmesi çok büyük değil, yani model zaten varsayılan haliyle de oldukça iyiydi.\n",
    "\n",
    "##### Fakat buu küçük iyileşme bile özellikle büyük veri setlerinde veya kritik uygulamalarda anlamlı olabilir.\n",
    "\n",
    "##### Optimize edilen parametreler genellikle modeli biraz daha genelleştirip aşırı öğrenmeyi engellemeye yarar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef8bc36-0ff0-4fba-bf78-451f71bc1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kodun çıktılarına ulaşamasamda kodu koymak istedim.\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Eğitim verisinin küçük bir alt kümesini kullan (performans için)\n",
    "X_sample = X_train[:1000]\n",
    "y_sample = y_train[:1000]\n",
    "\n",
    "# Daha dar ama etkili parametre aralığı\n",
    "param_dist_svr = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': uniform(1, 50),\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "random_search_svr = RandomizedSearchCV(\n",
    "    estimator=svr,\n",
    "    param_distributions=param_dist_svr,\n",
    "    n_iter=10,               # 10 kombinasyon\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit (hızlı örneklemle)\n",
    "random_search_svr.fit(X_sample, y_sample)\n",
    "\n",
    "# En iyi modelle tam test setinde tahmin\n",
    "print(\"En iyi parametreler (SVR):\", random_search_svr.best_params_)\n",
    "\n",
    "best_svr = random_search_svr.best_estimator_\n",
    "y_pred_best_svr = best_svr.predict(X_test)\n",
    "\n",
    "print(\"Optimize edilmiş SVR Performansı:\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_best_svr):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_best_svr):.2f}\")\n",
    "print(f\"R2: {r2_score(y_test, y_pred_best_svr):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72d1edaa-c3eb-47e4-bfa2-0113d94bb6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimize edilmiş Voting Regressor Performansı:\n",
      "MSE: 1257081815.37\n",
      "MAE: 16750.57\n",
      "R2: 0.8361\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "voting_model_optimized = VotingRegressor(\n",
    "    estimators=[\n",
    "        ('rf', best_rf),\n",
    "        ('lr', lr_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "voting_model_optimized.fit(X_train, y_train)\n",
    "y_pred_voting_opt = voting_model_optimized.predict(X_test)\n",
    "\n",
    "print(\"Optimize edilmiş Voting Regressor Performansı:\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_voting_opt):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_voting_opt):.2f}\")\n",
    "print(f\"R2: {r2_score(y_test, y_pred_voting_opt):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e244c5e-5a7d-4ab6-98ce-e695473910a8",
   "metadata": {},
   "source": [
    "MSE ve MAE değerleri Random Forest tek başına performansından biraz daha kötü görünüyor (Random Forest’ta MSE ~847M idi), ancak Voting Regressor hâlâ iyi sonuç veriyor.\n",
    "\n",
    "R² biraz azalmış (Random Forest’ta 0.8895’ti), yani açıklanan varyans biraz düşmüş.\n",
    "\n",
    "Burada Linear Regression modeli Voting’de etkili olmuş olabilir, çünkü Linear Regression genelde daha basit ve bazen tahminlerde sapmaya sebep olabilir.\n",
    "\n",
    "Yine de toplu modeli stabil ve makul performans sergiliyor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb362a3c-2821-4501-95c9-de743743b207",
   "metadata": {},
   "source": [
    "### Genel Yorum\n",
    "##### Random Forest Regressor, en iyi performansı gösterdi (R² ~0.89), yani bu veri seti için güçlü ve güvenilir bir model olarak öne çıktı. Hem karmaşık ilişkileri yakalayabiliyor hem de overfitting riski görece düşük.\n",
    "\n",
    "##### Lineer Regresyon modeli basit yapısı nedeniyle hız ve yorumlanabilirlik avantajı sağladı, ancak karmaşık ilişkileri yakalamada sınırlı kaldı (R² ~0.64). Yine de temel bir referans noktası olarak değerlendirilebilir.\n",
    "\n",
    "##### KNN Regressor ve Decision Tree Regressor makul performans sergiledi, ancak RF kadar güçlü değiller. KNN, büyük veri ve çok değişken olduğunda yavaş kalabilir.\n",
    "\n",
    "##### SVR bu veri setinde ve parametrelerle optimize edilmediğinde performansı zayıftı. Optimize edilmesi zaman alıyor ve pratik değil. Özellikle çok sayıda özellik varsa SVR’nin çalışması zorlaşıyor.\n",
    "\n",
    "##### Voting Regressor, farklı modellerin bir araya gelmesiyle dengeli bir tahmin sağladı. Ancak tek başına RF’nin performansına ulaşamadı.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f4ff6b-6c9d-43da-9357-506bb161cc90",
   "metadata": {},
   "source": [
    "# 2.BÖLÜM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb83c59-1c2e-4f62-b0d0-f751e60dfde4",
   "metadata": {},
   "source": [
    "\n",
    "### 1.GBM algoritmasının mantığı, zayıf öğrenici kavramı\n",
    "### 2.XGBoost'un farklılıkları (regularizasyon, erken durdurma, paralelleşme)\n",
    "### 3.Uygulama: XGBRegressor veya XGBClassifier\n",
    "### 4.Diğer modellerle karşılaştırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "38f43a19-34c6-40f5-87cf-e5d3b12c7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hedef değişeken sayısal olduğu için XDBRegressor kullanacağız.\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57bb9e8d-7252-4675-96f0-0763e31ea4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5c884b30-5189-428d-9633-bc6d34727342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor Performansı:\n",
      "MSE: 802277896.0207651\n",
      "MAE: 17375.963358839897\n",
      "R2: 0.8954049944877625\n"
     ]
    }
   ],
   "source": [
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"XGBRegressor Performansı:\")\n",
    "print(\"MSE:\", mse_xgb)\n",
    "print(\"MAE:\", mae_xgb)\n",
    "print(\"R2:\", r2_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802bc50-3350-4d56-aa22-be970139c80a",
   "metadata": {},
   "source": [
    "R² skoru oldukça yüksek (≈ %89.5), yani model hedef değişkendeki varyansın büyük bir kısmını açıklayabiliyor.\n",
    "\n",
    "MAE ve MSE değerleri, diğer regresyon modelleriyle karşılaştırıldığında oldukça düşük çıktı, bu da tahmin hatalarının az olduğunu gösteriyor.\n",
    "\n",
    "Model, Random Forest ile benzer doğrulukta, ancak daha hızlı çalışıyor ve daha esnek optimize edilebiliyor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5779881a-01f0-4378-af92-e0d9420ec415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "adfe2801-06ea-422d-a823-365e3a32f2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM Performansı:\n",
      "MSE: 814410853.8020935\n",
      "MAE: 17683.204224348596\n",
      "R2: 0.8938231788578969\n"
     ]
    }
   ],
   "source": [
    "# GBM modelini oluştur\n",
    "gbm = GradientBoostingRegressor(random_state=42)\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "# Tahmin yap\n",
    "y_pred_gbm = gbm.predict(X_test)\n",
    "\n",
    "# Performans metrikleri\n",
    "mse_gbm = mean_squared_error(y_test, y_pred_gbm)\n",
    "mae_gbm = mean_absolute_error(y_test, y_pred_gbm)\n",
    "r2_gbm = r2_score(y_test, y_pred_gbm)\n",
    "\n",
    "print(\"GBM Performansı:\")\n",
    "print(\"MSE:\", mse_gbm)\n",
    "print(\"MAE:\", mae_gbm)\n",
    "print(\"R2:\", r2_gbm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736eee58-96ff-499f-a508-38815655c6eb",
   "metadata": {},
   "source": [
    "\n",
    "XGBoost biraz daha iyi sonuç verdi, özellikle MSE ve R2 skorlarında (daha düşük MSE, daha yüksek R2).\n",
    "\n",
    "GBM ise biraz daha yavaş ama performansı oldukça yakın.\n",
    "\n",
    "İki model de güçlü zayıf öğrenici topluluk yöntemleri, fakat XGBoost'ta regularizasyon, erken durdurma ve paralelleşme gibi ek avantajlar bulunuyor, bu yüzden genellikle daha etkili ve hızlı çalışıyor.\n",
    "\n",
    "Her iki model de House Prices veri setinde başarılı tahminler yapıyor ve diğer klasik modellere göre (Lineer Regresyon, Random Forest vb.) daha iyi sonuçlar veriyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4fb77c4a-c57f-4e97-8ca9-e74d52769968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "En iyi parametreler (XGBoost): {'subsample': 0.8, 'reg_lambda': 2, 'reg_alpha': 0, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0.3, 'colsample_bytree': 0.8}\n",
      "MSE: 666938040.8612074\n",
      "MAE: 16123.388163527397\n",
      "R2: 0.913049578666687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "xgb = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3],\n",
    "    'reg_alpha': [0, 0.01, 0.1],\n",
    "    'reg_lambda': [1, 1.5, 2],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb, param_distributions=param_dist, n_iter=30,\n",
    "    scoring='neg_mean_squared_error', cv=3, verbose=2, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"En iyi parametreler (XGBoost):\", random_search.best_params_)\n",
    "\n",
    "best_xgb = random_search.best_estimator_\n",
    "\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred)}\")\n",
    "print(f\"R2: {r2_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f90cf20-a809-489d-a9f3-07524c6cd6cd",
   "metadata": {},
   "source": [
    "Optimize edilmiş XGBoost modelin performansı gayet başarılı görünüyor:\n",
    "\n",
    "MSE: 666,938,040 — Öncekinden daha düşük, yani hata azalmış.\n",
    "\n",
    "MAE: 16,123 — Ortalama hata da azalmış.\n",
    "\n",
    "R2: 0.913 — Model veriyi çok iyi açıklıyor, %91.3 varyansı yakalamış.\n",
    "\n",
    "Bu sonuç, önceki modellerle karşılaştırıldığında oldukça iyi bir iyileşme sağladı. XGBoost’un regularizasyon, erken durdurma ve güçlü ağaç tabanlı yapı özellikleri burada faydasını gösteriyor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46434bc-9747-4ef1-a3a8-9e288c8ff617",
   "metadata": {},
   "source": [
    "### Genel Yorum:\n",
    "Lineer Regresyon:\n",
    "R2 ~0.64 — Temel doğrusal model, makul ama sınırlı başarı.\n",
    "\n",
    "KNN Regressor:\n",
    "R2 ~0.70 — Komşuluk temelli biraz daha iyi ama yine sınırlı.\n",
    "\n",
    "Decision Tree Regressor:\n",
    "R2 ~0.76 — Tek ağaç ile daha iyi sonuç.\n",
    "\n",
    "Random Forest Regressor (optimize edilmiş):\n",
    "R2 ~0.89 — Çok sayıda ağacın birleşimiyle yüksek başarı.\n",
    "\n",
    "SVR:\n",
    "R2 negatif çıktı, yani kötü performans.\n",
    "\n",
    "Voting Regressor:\n",
    "R2 ~0.74 — Model kombinasyonu, orta seviyede.\n",
    "\n",
    "GBM:\n",
    "R2 ~0.89 — Random Forest’a yakın, güçlü ağaç tabanlı model.\n",
    "\n",
    "XGBoost (optimize edilmiş):\n",
    "R2 ~0.91 — En iyi performans, hatalar en düşük seviyede.\n",
    "\n",
    "Genel değerlendirme:\n",
    "XGBoost, hataları en iyi minimize eden ve veri varyansını en iyi açıklayan model olarak öne çıkıyor. Ardından Random Forest ve GBM geliyor. Doğrusal modeller ve KNN bu problem için yeterince esnek değil. SVR ise başarısız oldu.\n",
    "\n",
    "Bu sonuçlar, ağaç tabanlı yöntemlerin karmaşık ve yüksek boyutlu House Prices veri setlerinde daha başarılı olduğunu gösteriyor. Ayrıca XGBoost’un optimize edilmesiyle performans artışı net bir şekilde ortaya çıktı."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df3eafb-1c88-4624-9e68-2023ee761483",
   "metadata": {},
   "source": [
    "### 1. GBM Algoritmasının Mantığı ve Zayıf Öğrenici Kavramı\n",
    "Gradient Boosting Machine (GBM), topluluk öğrenmesi (ensemble learning) yöntemlerinden biridir ve zayıf öğrenicilerin (weak learners) ardışık olarak eğitilmesine dayanır. Burada zayıf öğrenici, genellikle tek başına çok güçlü olmayan ama biraz daha iyi tahmin yapabilen basit modellerdir; örneğin küçük derinlikli karar ağaçları.\n",
    "\n",
    "GBM, ilk olarak basit bir model (zayıf öğrenici) eğitir ve bu modelin hatalarını (residuals) hesaplar.\n",
    "\n",
    "Sonra, ikinci model bu hataları öğrenmeye çalışır; yani ilk modelin yapamadığını düzeltecek şekilde eğitilir.\n",
    "\n",
    "Bu süreç ardışık olarak devam eder, her yeni model öncekinin hatalarını azaltmak için eklenir.\n",
    "\n",
    "Sonuçta, zayıf öğrenicilerin birleşimiyle güçlü ve daha doğru bir model ortaya çıkar.\n",
    "\n",
    "Bu yöntem, özellikle karmaşık ve doğrusal olmayan ilişkilere sahip verilerde başarılıdır.\n",
    "\n",
    "### 2. XGBoost’un GBM’den Farkları\n",
    "XGBoost, GBM algoritmasının geliştirilmiş ve optimize edilmiş halidir. Temel farkları şunlardır:\n",
    "\n",
    "Regularizasyon (L1 ve L2): XGBoost, model karmaşıklığını kontrol etmek için regularizasyon terimleri ekler. Böylece aşırı uyum (overfitting) azaltılır.\n",
    "\n",
    "Erken Durdurma (Early Stopping): Model, doğrulama setindeki performans düşmeye başladığında eğitim otomatik olarak durdurulabilir. Bu da aşırı uyumu önler ve eğitim süresini kısaltır.\n",
    "\n",
    "Paralel İşlem: XGBoost, ağaç oluşturma işlemini paralel yaparak çok daha hızlı çalışır.\n",
    "\n",
    "Eksik Veri Desteği: XGBoost, eksik değerlerle doğal olarak başa çıkabilir, onları özel olarak işler.\n",
    "\n",
    "Daha İyi Optimizasyon: İkinci türev tabanlı optimizasyon yaparak daha hızlı ve etkili öğrenme sağlar.\n",
    "\n",
    "Sütun Örneklemesi: Rastgele olarak ağaç oluştururken kullanılan özelliklerin bir kısmını seçerek çeşitliliği artırır ve aşırı uyumu azaltır.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b095a3e6-8c0b-4fdd-b7f6-01f8ede6b328",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e99ef1-030e-417b-9fdb-8f7e27c99696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba7873-acda-4fb2-9a87-6e8ee4597a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
